{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "next_word_prediction.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfKE3FP9zxaS"
      },
      "source": [
        "import nltk\n",
        "import pickle\n",
        "from nltk.tokenize import word_tokenize,sent_tokenize\n",
        "from keras.preprocessing.text import Tokenizer\n",
        "from nltk.corpus import gutenberg\n",
        "import numpy as np\n",
        "import re\n",
        "import tensorflow as tf\n",
        "from keras.utils import to_categorical\n",
        "from keras.preprocessing.sequence import pad_sequences"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m3mS0XAhQmhd"
      },
      "source": [
        "**Loading the dataset**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajeTcwxEEQOU",
        "outputId": "e82a45f1-4c62-492f-b193-57543341885a"
      },
      "source": [
        "nltk.download('punkt')\n",
        "nltk.download('gutenberg')\n",
        "byrant=gutenberg.raw('bryant-stories.txt')\n",
        "whitman=gutenberg.raw('whitman-leaves.txt')\n",
        "burgass=gutenberg.raw('burgess-busterbrown.txt')\n",
        "chesteron=gutenberg.raw('chesterton-ball.txt')\n",
        "total_txt=byrant"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/gutenberg.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iJ8uu15mQxl9"
      },
      "source": [
        "**Text_preprocessing**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpjDpn7vG5Kv"
      },
      "source": [
        "punc_removed=re.sub(r'\\W+', ' ', total_txt).lower()\n",
        "words = nltk.word_tokenize(punc_removed)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uM0JYST90yfl"
      },
      "source": [
        "for x in words :\n",
        "  if(len(x)<2 and x != 'a' and x != 'i'  ):\n",
        "    words.remove(x)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "krItfO-YRggZ",
        "outputId": "c3907ded-b0a0-4c26-ca71-50bf6b206af8"
      },
      "source": [
        "unique=list(set(words))\n",
        "len(unique)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3890"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lnGjZbMi6MrN"
      },
      "source": [
        "train_len = 4\n",
        "text_sequences = []\n",
        "for i in range(train_len,len(words)):\n",
        "  seq = words[i-train_len:i]\n",
        "  text_sequences.append(seq)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h-O96wFIP01F"
      },
      "source": [
        "sequences = {}\n",
        "count = 1\n",
        "for i in range(len(words)):\n",
        "  if words[i] not in sequences:\n",
        "    sequences[words[i]] = count\n",
        "    count += 1"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBDxvVnc0nT5"
      },
      "source": [
        "tokenizer = Tokenizer()\n",
        "tokenizer.fit_on_texts(text_sequences)\n",
        "sequences = tokenizer.texts_to_sequences(text_sequences)\n",
        "vocabulary_size = len(tokenizer.word_counts)+1"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2mj1qYW8IDp"
      },
      "source": [
        "filename = 'token'\n",
        "outfile = open(filename,'wb')\n",
        "pickle.dump(tokenizer,outfile)\n",
        "outfile.close()"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8cUrVQVFkUg"
      },
      "source": [
        "n_sequences = np.empty([len(sequences),train_len], dtype='int32')\n",
        "for i in range(len(sequences)):\n",
        "  n_sequences[i] = sequences[i]\n",
        "train_inputs = n_sequences[:,:-1]\n",
        "train_targets = n_sequences[:,-1]\n",
        "train_targets = to_categorical(train_targets, num_classes=vocabulary_size)\n",
        "seq_len = train_inputs.shape[1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R7vbi_qWQ-Zl"
      },
      "source": [
        "**Loading the tensorflow hub universal senetence encoder**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gglBw5wWlMCD"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder-large/5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olkk5HIl4nCP"
      },
      "source": [
        "seq_dict=embed(unique)\n",
        "seq_dict=np.array(seq_dict)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUGomJHv-0dZ"
      },
      "source": [
        "embedding_layer =tf.keras.layers.Embedding(\n",
        "    seq_dict.shape[0],\n",
        "    512,\n",
        "    weights=[seq_dict],\n",
        "    input_length=seq_len,\n",
        "    trainable=False,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "INjYBhVWYm7o"
      },
      "source": [
        "**`Model building and transfer learning**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71ZAZH77D3tn"
      },
      "source": [
        "input1 = tf.keras.Input(shape=seq_len,name=\"input1\")\n",
        "emb= embedding_layer(input1)\n",
        "bls1=tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(256,return_sequences=True))(emb)\n",
        "bls2=tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128))(bls1)\n",
        "fc1=tf.keras.layers.Dense(64, activation='relu')(bls2)\n",
        "output=tf.keras.layers.Dense(vocabulary_size, activation='softmax')(fc1)\n",
        "model=tf.keras.models.Model(inputs=input1,outputs=output)\n",
        "print(model.summary())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "02snUWSZEL2j"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(train_inputs,train_targets,epochs=32,verbose=1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpnVE9nVRwvl"
      },
      "source": [
        "emb.trainable=True"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qda3Q-N2Th9-"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "model.fit(train_inputs,train_targets,epochs=16,verbose=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j38OVVVePrX1"
      },
      "source": [
        "model.save('./drive/MyDrive/saved_models/NWP_BILSTM.h5')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}